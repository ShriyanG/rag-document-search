# RAG Document Search

A modular, production-style **Retrieval-Augmented Generation (RAG)** system for querying private PDF documents using dense retrieval and large language models.

This project is designed to mirror real-world ML systems rather than notebook-only prototypes. It emphasizes **clean architecture**, **token-aware retrieval**, and **reproducible pipelines**.

---

## âœ¨ Features

* End-to-end RAG pipeline: **ingestion â†’ embedding â†’ indexing â†’ retrieval â†’ generation**
* Token-aware retrieval that dynamically adapts context size to model limits
* Local LLM support (CPU-friendly) with pluggable backends
* FAISS-based vector search for efficient similarity retrieval
* Clean, subcommand-based CLI for pipeline setup and querying
* Modular codebase structured for extensibility and experimentation

---

## ğŸ—ï¸ Project Architecture

```
src/
â”œâ”€â”€ main.py                # CLI entry point
â”œâ”€â”€ rag.py                 # RAG orchestration logic
â”‚
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ llm/               # LLM abstractions (Local, OpenAI, etc.)
â”‚   â””â”€â”€ data/              # Data ingestion (PDF parsing)
â”‚
â”œâ”€â”€ retrieval/
â”‚   â”œâ”€â”€ embeddings.py      # Embedding generation
â”‚   â”œâ”€â”€ indexing.py        # FAISS index construction
â”‚   â””â”€â”€ retrieve.py        # Similarity search
â”‚
â”œâ”€â”€ utils/                 # Token estimation, helpers
â””â”€â”€ config.py              # Model and system configuration
```

The pipeline stages are intentionally decoupled to allow incremental rebuilding and easier debugging.

---

## ğŸš€ Getting Started

### 1. Create a Virtual Environment

```bash
python -m venv venv
source venv/bin/activate
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ”§ Command-Line Interface (CLI)

The system exposes a clean CLI for both **pipeline setup** and **query execution**.

### Pipeline Setup

Run the full ingestion â†’ embedding â†’ indexing pipeline:

```bash
python src/main.py setup
```

Skip individual stages if artifacts already exist:

```bash
# Skip PDF ingestion
python src/main.py setup --skip-ingestion

# Skip embedding generation
python src/main.py setup --skip-embedding

# Skip FAISS index building
python src/main.py setup --skip-indexing
```

This design enables **incremental rebuilds**, which mirrors real-world ML workflows.

---

### Query the RAG System

Ask questions over the indexed document corpus:

```bash
python src/main.py query "What is attention?"
```

Control retrieval depth:

```bash
python src/main.py query "Explain transformers" --top-k 5
```

The system retrieves the most relevant document chunks, formats them into a context window, and generates an answer using the configured LLM.

---

## ğŸ§  Design Highlights

* **Production-style CLI** using subcommands (`setup`, `query`)
* **Stage-skippable pipeline** to avoid unnecessary recomputation
* **Token-aware retrieval logic** to respect LLM context limits
* **Clear abstraction boundaries** between data, retrieval, and generation
* **Model-agnostic LLM interface** for easy backend swapping

---

## ğŸ“¦ Models & Retrieval

* **Embeddings**: Sentence-transformer based dense embeddings
* **Vector Store**: FAISS for fast similarity search
* **LLMs**: Local transformer models (e.g. FLAN-T5) or API-backed models

The retrieval depth (`top-k`) can be dynamically adjusted based on estimated token usage to prevent context overflow.

---

## ğŸ¯ Motivation

Most RAG examples exist only as notebooks. This project focuses on building a **maintainable, extensible system** that reflects how retrieval and generation pipelines are structured in production ML environments.

The goal is to demonstrate:

* Systems thinking for ML applications
* Practical constraints such as token limits and recomputation cost
* Clean interfaces between pipeline stages

---

## ğŸ› ï¸ Future Work

* FastAPI service for programmatic access
* Reranking with cross-encoders
* Streaming or chunk-aware generation
* Hybrid (sparse + dense) retrieval
* Evaluation harness for retrieval quality

---

## ğŸ“„ License

MIT License
